#!/usr/bin/env python
# -*- coding: utf-8 -*-

# .env ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
from dotenv import load_dotenv, find_dotenv
load_dotenv(find_dotenv())

import os
import torch
from PIL import Image
import streamlit as st
from openai import OpenAI
from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ç’°å¢ƒå¤‰æ•°ã®å–å¾—
API_KEY    = os.getenv("OPENAI_API_KEY")
MODEL_DIR  = os.getenv("FINETUNED_MODEL_DIR", "./instructblip_finetuned_no_image_token")
CHAT_MODEL = os.getenv("CHATGPT_MODEL_NAME", "gpt-4o-mini")
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# APIã‚­ãƒ¼æœªè¨­å®šæ™‚ã¯åœæ­¢
if not API_KEY:
    st.error("ğŸš¨ ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    st.stop()

# OpenAI v1 client åˆæœŸåŒ–
client = OpenAI(api_key=API_KEY)

# è¨ºæ–­å¯èƒ½ãªç–¾æ‚£ã‚¯ãƒ©ã‚¹
CLASSES = [
    "ADM", "Basal_cell_carcinoma", "Ephelis", "Malignant_melanoma",
    "Melasma", "Nevus", "Seborrheic_keratosis", "Solar_lentigo"
]
# ç–¾æ‚£èª¬æ˜ãƒãƒƒãƒ—
DISEASE_EXPLANATIONS = {
    "ADM": "ç•°å‹é»’å­ç—‡ - è‰²ç´ æ€§ç—…å¤‰ã§ã€ãƒ¡ãƒ©ãƒãƒ¼ãƒã®å‰é§†ç—…å¤‰ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
    "Basal_cell_carcinoma": "åŸºåº•ç´°èƒç™Œ - æœ€ã‚‚ä¸€èˆ¬çš„ãªçš®è†šãŒã‚“ã§ã€ã‚†ã£ãã‚Šæˆé•·ã—å‘¨å›²ã‚’ä¾µé£Ÿã—ã¾ã™ã€‚",
    "Ephelis": "ãã°ã‹ã™ - éºä¼ã¨ç´«å¤–ç·šã«ã‚ˆã‚Šç”Ÿã˜ã‚‹è¤è‰²æ–‘ã€‚",
    "Malignant_melanoma": "æ‚ªæ€§é»’è‰²è…« - æœ€ã‚‚å±é™ºãªçš®è†šãŒã‚“ã§æ—©æœŸè¨ºæ–­ãŒé‡è¦ã€‚",
    "Melasma": "è‚æ–‘ - ãƒ›ãƒ«ãƒ¢ãƒ³å¤‰åŒ–ã‚„ç´«å¤–ç·šèª˜ç™ºã®èŒ¶è¤è‰²æ²ˆç€ã€‚",
    "Nevus": "æ¯æ–‘/ã»ãã‚ - è‰¯æ€§è‰²ç´ æ€§ç—…å¤‰ã€‚",
    "Seborrheic_keratosis": "è„‚æ¼æ€§è§’åŒ–ç—‡ - è‰¯æ€§å¢—æ®–ã§ãƒ¯ãƒƒã‚¯ã‚¹çŠ¶ã€‚",
    "Solar_lentigo": "æ—¥å…‰æ€§é»’å­ - ç´«å¤–ç·šæ›éœ²ã«ã‚ˆã‚‹è¤è‰²æ–‘ã€‚"
}


def get_class_index_from_generated(text: str) -> int:
    """ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ä¸€è‡´ã§ CLASSES ã® index ã‚’è¿”ã™"""
    low = text.lower()
    for i, cls in enumerate(CLASSES):
        if cls.lower() in low:
            return i
    return -1


def load_local_model():
    """ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ³ãƒ¢ãƒ‡ãƒ«å„ªå…ˆãƒ­ãƒ¼ãƒ‰ã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"""
    LOCAL_DIR = MODEL_DIR
    if os.path.isdir(LOCAL_DIR):
        st.info(f"ğŸ”„ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ³æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {LOCAL_DIR}")
        model     = InstructBlipForConditionalGeneration.from_pretrained(LOCAL_DIR)
        processor = InstructBlipProcessor.from_pretrained("Salesforce/instructblip-flan-t5-xl", use_fast=False)
    else:
        st.warning(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€æœªç™ºè¦‹: {LOCAL_DIR} -> ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ­ãƒ¼ãƒ‰")
        processor = InstructBlipProcessor.from_pretrained("Salesforce/instructblip-flan-t5-xl", use_fast=False)
        model     = InstructBlipForConditionalGeneration.from_pretrained("Salesforce/instructblip-flan-t5-xl")

    # ãƒ‡ãƒã‚¤ã‚¹é¸æŠ
    if torch.cuda.is_available():
        device = torch.device("cuda"); st.sidebar.success("GPU ä½¿ç”¨ä¸­")
    elif torch.backends.mps.is_available():
        device = torch.device("mps");  st.sidebar.success("MPS ä½¿ç”¨ä¸­")
    else:
        device = torch.device("cpu");  st.sidebar.info("CPU ä½¿ç”¨ä¸­")

    # å‰å‡¦ç†ã‚µã‚¤ã‚º
    processor.image_processor.size      = {"height":224, "width":224}
    processor.image_processor.crop_size = {"height":224, "width":224}

    model.to(device)
    model.eval()
    return model, processor, device


def diagnose_together(model, processor, device, image, symptoms, exam):
    """
    InstructBLIP ã®ç”Ÿã®å‡ºåŠ›ã¨è‡¨åºŠæƒ…å ±ã‚’åˆã‚ã›ã¦
    ChatGPT ã«ä¸€ç·’ã«è€ƒãˆã¦ã‚‚ã‚‰ã„æœ€çµ‚è¨ºæ–­ã‚’è¿”ã™
    """
    # --- InstructBLIP æ¨è«– ---
    img = image.convert("RGB")
    prompt = (
        f"ã“ã®æ‚£è€…ã•ã‚“ã®å†™çœŸã‚’è¨ºæ–­ã—ã¦ãã ã•ã„ã€‚\n"
        f"ç—‡çŠ¶çµŒé: {symptoms}\n"
        f"è§¦è¨ºçµæœ: {exam}\n"
        f"â†’ ã¾ãšã¯ InstructBLIP ãƒ¢ãƒ‡ãƒ«ã®åˆ¤æ–­ã‚’ç”Ÿã®æ–‡ç« ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
    )
    inputs = processor(images=img, text=prompt, return_tensors="pt")
    inputs = {k: v.to(device) for k, v in inputs.items()}
    with torch.no_grad():
        out_ids = model.generate(**inputs, num_beams=4, early_stopping=True, max_length=128)
    raw_text = processor.tokenizer.batch_decode(out_ids, skip_special_tokens=True)[0]

    # --- ChatGPT é€£æº ---
    system = "ã‚ãªãŸã¯ç†Ÿç·´ã®çš®è†šç§‘åŒ»ã§ã™ã€‚"
    user_msg = (
        f"ä»¥ä¸‹ã¯ InstructBLIP ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã§ã™ã€‚\n"
        f"{raw_text}\n\n"
        f"ã“ã‚Œã¨ã€ä»¥ä¸‹ã®è‡¨åºŠæƒ…å ±ã‚’åˆã‚ã›ã¦ä¸€ç·’ã«è€ƒãˆã€æœ€çµ‚çš„ãªè¨ºæ–­ã¨ãã®ç†ç”±ã‚’ä¸€ã¤ã®æ–‡ç« ã§ç¤ºã—ã¦ãã ã•ã„ã€‚\n\n"
        f"ã€ç—‡çŠ¶çµŒéã€‘: {symptoms}\n"
        f"ã€è§¦è¨ºçµæœã€‘: {exam}"
    )
    resp = client.chat.completions.create(
        model=CHAT_MODEL,
        messages=[
            {"role": "system", "content": system},
            {"role": "user",   "content": user_msg},
        ],
        temperature=0.5,
        max_tokens=256,
    )
    return resp.choices[0].message.content.strip()


def main():
    st.set_page_config(page_title="çš®è†šç–¾æ‚£è¨ºæ–­ã‚¢ãƒ—ãƒª", page_icon="ğŸ¥", layout="wide")
    st.title("ğŸ¥ çš®è†šç–¾æ‚£è¨ºæ–­ (InstructBLIP + ChatGPT)")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ã“ã®ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦")
        st.info("ä¸€æ¬¡è¨ºæ–­ã« Fine-tuned InstructBLIPã€æœ€çµ‚è¨ºæ–­ã« ChatGPT API(v1) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚çµæœã¯å‚è€ƒæƒ…å ±ã§ã™ã€‚")
        st.header("è¨ºæ–­å¯èƒ½ç–¾æ‚£")
        for cls in CLASSES:
            st.write(f"- **{cls}**: {DISEASE_EXPLANATIONS[cls]}")

    col1, col2 = st.columns(2)
    with col1:
        img_file = st.file_uploader("å†™çœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg","png","jpeg"])
        symptoms = st.text_area("ç—‡çŠ¶ã®çµŒé", height=120)
        exam     = st.text_area("è§¦è¨ºçµæœ", height=80)
        btn      = st.button("è¨ºæ–­é–‹å§‹", type="primary", disabled=img_file is None)

    if btn and img_file:
        img = Image.open(img_file)
        model, processor, device = load_local_model()
        # InstructBLIP ã®å‡ºåŠ›ã¨è‡¨åºŠæƒ…å ±ã‚’ã¾ã¨ã‚ã¦ä¸€ç·’ã«è¨ºæ–­
        diagnosis = diagnose_together(model, processor, device, img, symptoms, exam)

        with col2:
            st.subheader("è¨ºæ–­çµæœ")
            st.markdown(diagnosis)
            st.image(img, caption="å…¥åŠ›ç”»åƒ", use_column_width=True)

if __name__ == "__main__":
    main()
