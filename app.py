#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
åŒ»ç™‚è¨ºæ–­ã‚¢ãƒ—ãƒª - InstructBLIP + ChatGPT API(v1) ã‚’ä½¿ç”¨ã—ãŸçš®è†šç–¾æ‚£è¨ºæ–­
1) ãƒ­ãƒ¼ã‚«ãƒ«ã® Fine-tuned InstructBLIP ã§ä¸€æ¬¡è¨ºæ–­
2) OpenAI v1 API client ã§æœ€çµ‚è¨ºæ–­ã‚’å–å¾—
"""

import os
import torch
from PIL import Image
import streamlit as st
import openai
from openai import OpenAI
from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration

# ChatGPT API ã‚­ãƒ¼å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•°ï¼‰
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("ğŸš¨ ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    st.stop()

# OpenAI v1 client åˆæœŸåŒ–
client = OpenAI(api_key=api_key)

# è¨ºæ–­å¯èƒ½ãªç–¾æ‚£ã‚¯ãƒ©ã‚¹
CLASSES = [
    "ADM", "Basal_cell_carcinoma", "Ephelis", "Malignant_melanoma",
    "Melasma", "Nevus", "Seborrheic_keratosis", "Solar_lentigo"
]
# ç–¾æ‚£èª¬æ˜ãƒãƒƒãƒ—
DISEASE_EXPLANATIONS = {
    "ADM": "ç•°å‹é»’å­ç—‡ - è‰²ç´ æ€§ç—…å¤‰ã§ã€ãƒ¡ãƒ©ãƒãƒ¼ãƒã®å‰é§†ç—…å¤‰ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
    "Basal_cell_carcinoma": "åŸºåº•ç´°èƒç™Œ - æœ€ã‚‚ä¸€èˆ¬çš„ãªçš®è†šãŒã‚“ã§ã€ã‚†ã£ãã‚Šæˆé•·ã—å‘¨å›²ã‚’ä¾µé£Ÿã—ã¾ã™ã€‚",
    "Ephelis": "ãã°ã‹ã™ - éºä¼ã¨ç´«å¤–ç·šã«ã‚ˆã‚Šç”Ÿã˜ã‚‹è¤è‰²æ–‘ã€‚",
    "Malignant_melanoma": "æ‚ªæ€§é»’è‰²è…« - æœ€ã‚‚å±é™ºãªçš®è†šãŒã‚“ã§æ—©æœŸè¨ºæ–­ãŒé‡è¦ã€‚",
    "Melasma": "è‚æ–‘ - ãƒ›ãƒ«ãƒ¢ãƒ³å¤‰åŒ–ã‚„ç´«å¤–ç·šèª˜ç™ºã®èŒ¶è¤è‰²æ²ˆç€ã€‚",
    "Nevus": "æ¯æ–‘/ã»ãã‚ - è‰¯æ€§è‰²ç´ æ€§ç—…å¤‰ã€‚",
    "Seborrheic_keratosis": "è„‚æ¼æ€§è§’åŒ–ç—‡ - è‰¯æ€§å¢—æ®–ã§ãƒ¯ãƒƒã‚¯ã‚¹çŠ¶ã€‚",
    "Solar_lentigo": "æ—¥å…‰æ€§é»’å­ - ç´«å¤–ç·šæ›éœ²ã«ã‚ˆã‚‹è¤è‰²æ–‘ã€‚"
}


def get_class_index_from_generated(text: str) -> int:
    """ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ä¸€è‡´ã§ CLASSES ã® index ã‚’è¿”ã™"""
    low = text.lower()
    for i, cls in enumerate(CLASSES):
        if cls.lower() in low:
            return i
    return -1


def load_local_model():
    """ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ³ãƒ¢ãƒ‡ãƒ«å„ªå…ˆãƒ­ãƒ¼ãƒ‰ã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"""
    LOCAL_DIR = "./instructblip_finetuned_no_image_token"
    if os.path.isdir(LOCAL_DIR):
        st.info(f"ğŸ”„ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ³æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {LOCAL_DIR}")
        model     = InstructBlipForConditionalGeneration.from_pretrained(LOCAL_DIR)
        processor = InstructBlipProcessor.from_pretrained("Salesforce/instructblip-flan-t5-xl", use_fast=False)
    else:
        st.warning(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€æœªç™ºè¦‹: {LOCAL_DIR} -> ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ­ãƒ¼ãƒ‰")
        processor = InstructBlipProcessor.from_pretrained("Salesforce/instructblip-flan-t5-xl", use_fast=False)
        model     = InstructBlipForConditionalGeneration.from_pretrained("Salesforce/instructblip-flan-t5-xl")

    # ãƒ‡ãƒã‚¤ã‚¹
    if torch.cuda.is_available():
        device = torch.device("cuda"); st.sidebar.success("GPU ä½¿ç”¨ä¸­")
    elif torch.backends.mps.is_available():
        device = torch.device("mps");  st.sidebar.success("MPS ä½¿ç”¨ä¸­")
    else:
        device = torch.device("cpu");  st.sidebar.info("CPU ä½¿ç”¨ä¸­")

    # å‰å‡¦ç†ã‚µã‚¤ã‚º
    processor.image_processor.size      = {"height":224, "width":224}
    processor.image_processor.crop_size = {"height":224, "width":224}

    model.to(device)
    model.eval()
    return model, processor, device


def local_inference(model, processor, device, image, symptoms, exam):
    """ä¸€æ¬¡è¨ºæ–­ï¼šç”»åƒï¼‹ãƒ†ã‚­ã‚¹ãƒˆ -> ãƒ©ãƒ™ãƒ«ï¼†èª¬æ˜"""
    img = image.convert("RGB")
    prompt = f"USER: ã“ã®æ‚£è€…ã•ã‚“ã®å†™çœŸã‚’è¨ºæ–­ã—ã¦ãã ã•ã„ã€‚\nç—‡çŠ¶çµŒé: {symptoms}\nè§¦è¨ºçµæœ: {exam}\nASSISTANT:"
    inputs = processor(images=img, text=prompt, return_tensors="pt")
    inputs = {k: v.to(device) for k,v in inputs.items()}
    with torch.no_grad():
        out_ids = model.generate(**inputs, num_beams=4, early_stopping=True, max_length=128)
    text = processor.tokenizer.batch_decode(out_ids, skip_special_tokens=True)[0]
    idx  = get_class_index_from_generated(text)
    if idx>=0:
        label = CLASSES[idx]
        expl  = DISEASE_EXPLANATIONS[label]
    else:
        label = "ä¸æ˜"
        expl  = "ãƒ¢ãƒ‡ãƒ«ãŒç–¾æ‚£ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å°‚é–€åŒ»ã¸ã€‚"
    return label, expl, text


def chatgpt_refine(label, expl, symptoms, exam):
    """ä¸€æ¬¡è¨ºæ–­ã‚’ã‚‚ã¨ã« ChatGPT API(v1) ã§æœ€çµ‚è¨ºæ–­å–å¾—"""
    system = "ã‚ãªãŸã¯çš®è†šç§‘åŒ»ã§ã™ã€‚ä¸€æ¬¡è¨ºæ–­ã¨æƒ…å ±ã‹ã‚‰æœ€çµ‚è¨ºæ–­ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚"
    user   = f"ä¸€æ¬¡è¨ºæ–­: {label}\nè¨ºæ–­ç†ç”±: {expl}\nç—‡çŠ¶çµŒé: {symptoms}\nè§¦è¨ºçµæœ: {exam}"
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system},
            {"role": "user",   "content": user},
        ],
        temperature=0.5,
        max_tokens=256,
    )
    return resp.choices[0].message.content.strip()


def main():
    st.set_page_config(page_title="çš®è†šç–¾æ‚£è¨ºæ–­ã‚¢ãƒ—ãƒª", page_icon="ğŸ¥", layout="wide")
    st.title("ğŸ¥ çš®è†šç–¾æ‚£è¨ºæ–­ (InstructBLIP + ChatGPT)")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ã“ã®ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦")
        st.info("ä¸€æ¬¡è¨ºæ–­ã« Fine-tuned InstructBLIPã€æœ€çµ‚è¨ºæ–­ã« ChatGPT API(v1) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚çµæœã¯å‚è€ƒæƒ…å ±ã§ã™ã€‚")
        st.header("è¨ºæ–­å¯èƒ½ç–¾æ‚£")
        for cls in CLASSES:
            st.write(f"- **{cls}**: {DISEASE_EXPLANATIONS[cls]}")

    col1, col2 = st.columns(2)
    with col1:
        img_file = st.file_uploader("å†™çœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg","png","jpeg"])
        symptoms = st.text_area("ç—‡çŠ¶ã®çµŒé", height=120)
        exam     = st.text_area("è§¦è¨ºçµæœ", height=80)
        btn      = st.button("è¨ºæ–­é–‹å§‹", type="primary", disabled=img_file is None)

    if btn and img_file:
        img = Image.open(img_file)
        model, processor, device = load_local_model()
        label, expl, raw = local_inference(model,processor,device,img,symptoms,exam)
        final = chatgpt_refine(label,expl,symptoms,exam)

        with col2:
            st.subheader("ä¸€æ¬¡è¨ºæ–­ (InstructBLIP)")
            st.markdown(f"**ãƒ©ãƒ™ãƒ«**: {label}")
            st.markdown(f"**èª¬æ˜**: {expl}")
            st.code(raw)
            st.subheader("æœ€çµ‚è¨ºæ–­ (ChatGPT)")
            st.markdown(final)
            st.image(img, caption="å…¥åŠ›ç”»åƒ", use_column_width=True)

if __name__ == "__main__":
    main()
